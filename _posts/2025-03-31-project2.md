---
layout: post
title: Project 2 - Theme Park AI Assistant
category: HCI project diary
---

## Introduction

Project 2 focused on developing a Human-Robot Interaction (HRI) solution for hospitality services. Our team created "Tom," an AI assistant for theme park visitors that helps with navigation, emergency response, and access to information.

## Project Description

The project required us to:
- Observe and interview users to identify scenarios where a voice agent/chatbot could facilitate hospitality services
- Construct a Point of View (POV) and brainstorm ideas
- Create a working prototype of the conversation part of our HRI solution
- Compile a video demo and conduct usability testing
- Present our solution in class

### Empathize

We conducted interviews with people who had recently visited theme parks to understand their pain points:

- **Navigation challenges**: Difficulty finding attractions and facilities in large parks
- **Information access**: Trouble getting real-time information about shows, wait times, and services
- **Emergency concerns**: Anxiety about what to do in case of lost items, missing children, or medical emergencies
- **Crowd management**: Frustration with crowded areas and long wait times

Here are some interview insights:

![Interview Screenshot](/HCI/assets/interview2.png)
*Interview with a recent theme park visitor*

### Ideation

After identifying key user needs, we brainstormed potential solutions:

We constructed our POV statement:
> "Theme park visitors need a real-time, location-aware assistant that helps them navigate efficiently, responds to emergencies, and enhances their overall experience because large parks can be overwhelming, stressful, and difficult to navigate."

### Prototype Development

We developed "Tom," an AI assistant with the following key features:

1. **Intelligent Navigation**
   - Location-aware directions
   - Real-time crowd monitoring
   - Alternative route suggestions

2. **Emergency Management System**
   - Protocol for lost children
   - Medical emergency response
   - Lost item reporting

3. **Information Access**
   - Attraction details
   - Show schedules
   - Facility information

We implemented the prototype using:
- Azure OpenAI for natural language understanding
- Speech-to-Text and Text-to-Speech for voice interaction
- Graph-based navigation system for pathfinding
- State management for tracking user context

### User Testing

We conducted usability testing with participants who were not part of our team:

![User Testing](/HCI/assets/usertesting.png)
*Screenshot from usability testing session*

Key feedback:
- Users particularly appreciated the emergency response protocols
- The shortest path feature and crowd level information were highly valued
- Navigation accuracy was praised
- Lost item reporting process was intuitive
- Some users noted that the AI responses didn't sound natural enough for voice output

## Learning and Execution Process

### Technical Implementation

We programmed the chatbot to handle various scenarios:

1. **Basic Information Queries**
   - Information about attractions, shows, and facilities

2. **Navigation Requests**
   - Directions between locations with consideration for crowd levels

3. **Emergency Scenarios**
   - Protocols for lost items, missing children, and medical emergencies

4. **Location Awareness**
   - Tracking user position to provide contextual assistance


### Use of AI

We used AI tools in several ways during this project:
- Generated test cases for our chatbot using ChatGPT
- Refined our prompt engineering for better responses
- Used Azure OpenAI API for the core natural language understanding
- [Link to AI tool usage documentation](https://poe.com/s/XSybo2bJeBpY2mAuW81b)

## Personal Contributions and Achievements

My primary contributions to this project included:
- Designing the emergency response protocols
- Implementing the navigation graph for efficient pathfinding
- Conducting 3 user interviews to gather initial requirements
- Creating test cases to verify different aspects of the chatbot
- Participating in the usability testing and documenting feedback

## Personal Reflection

Working on this HRI project taught me valuable lessons about designing conversational interfaces:

1. **Context matters**: The assistant needs to remember previous interactions to be truly helpful.

2. **Error handling is crucial**: Users don't always express themselves clearly, so robust error handling is essential.

3. **Voice vs. text**: What works well in text doesn't always sound natural when spoken, requiring different optimization strategies.

4. **Empathy in design**: Understanding user anxiety in emergency situations helped us design more compassionate responses.

I found the emergency protocol development particularly interesting, as it required balancing efficiency with empathy. The positive user feedback about this feature was especially rewarding, confirming that we had successfully addressed a real pain point for theme park visitors.

For future improvements, I would focus on making the AI responses sound more natural for voice output, which was the main criticism in our user testing.



